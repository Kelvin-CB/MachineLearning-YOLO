### Author: Kelvin Carvalho Bomfim

## Sele√ß√£o Voxar: Projeto de Machine Learning utilizando Modelo YOLO 
* Revis√£o do funcionamento de modelos YOLO, hiperpar√¢metros, optimiza√ß√£o, loss function, taxa de aprendizagem.
* Implementa√ß√£o do modelo YOLOv5 pr√© treinado com o dataset COCO128.
* Treinamento e teste de modelos customizados a partir de diferentes datasets. 
* Pr√©-Processamento dos dados com o RoboFlow. 
* An√°lise do treinamento em tempo real com WandB. 

## C√≥digo e recursos utilizados 
**Python Version:** 3.9  
**Libs:** pandas, numpy, matplotlib, pyTorch(CPU to train/GPU to predict), OpenCV                                                          
**COCO128:** https://www.kaggle.com/datasets/ultralytics/coco128                                                         
**BCCD:** https://github.com/Shenggan/BCCD_Dataset                                                         
**Snail Custom Dataset:** /SnailDataset                                                       
**LabelImg:** https://github.com/tzutalin/labelImg                                                       
**RoboFlow:** https://roboflow.com/                                                       
**WandB:** https://https://wandb.ai/                                                       

## M√≥dulo B√°sico: 1
O modelo escolhido para o case, foi o YOLOv5 pr√©-treinado no dataset COCO128, uma vers√£o reduzida do COCO Dataset, o mesmo mostrou-se de f√°cil manipula√ß√£o e bem intuitivo, o teste foi feito nas imagens pr√© dispon√≠veis do mesmo:

```python
import torch
from matplotlib import pyplot as plt
import numpy as np
import cv2
```

```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s') #Modelo pr√©-treinado com o COCO128
```

```python
img = "Voxar/yolov5/data/images/bus.jpg"
results = model(img)
results.print()
```
![alt text](images/bus.jpg)

```
image 1/1: 1080x810 4 persons, 1 bus #Resultado da reconhecimento de objetos na imagem
Speed: 518.7ms pre-process, 303.5ms inference, 435.0ms NMS per image at shape (1, 3, 640, 480)
```

## M√≥dulo B√°sico: 2
O backgroud por tr√°s dos modelos YOLO se d√° atrav√©s da subdivis√£o de uma imagem em N peda√ßos, formando um grid SxS = N, cada um desses n peda√ßos √© responsavel pela detec√ß√£o e localiza√ß√£o de objetos no seu conte√∫do. Como a detec√ß√£o e reconhecimento acontecem simultaneamente para cada N peda√ßo, o consumo de poder computacional √© reduzido, mas em consequ√™ncia, ocorre um aumento no numero de predi√ß√µes duplicadas (Ex: um objeto estar subdivido entre mais de um N peda√ßo), este problema √© contornado atrav√©s do uso de Non Maximal Suppression (IoU), dessa forma conseguindo reduzir o numero de predi√ß√µes duplicadas sem utilizar valores m√°ximo globais como par√¢metro.

![alt text](images/iou.png)

Arquivo de hiperparametros:
```python
# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
# Hyperparameters for medium-augmentation COCO training from scratch
# python train.py --batch 32 --cfg yolov5m6.yaml --weights '' --data coco.yaml --img 1280 --epochs 300
# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials

lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)
lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.937  # SGD momentum/Adam beta1
weight_decay: 0.0005  # optimizer weight decay 5e-4
warmup_epochs: 3.0  # warmup epochs (fractions ok)
warmup_momentum: 0.8  # warmup initial momentum
warmup_bias_lr: 0.1  # warmup initial bias lr
box: 0.05  # box loss gain
cls: 0.3  # cls loss gain
cls_pw: 1.0  # cls BCELoss positive_weight
obj: 0.7  # obj loss gain (scale with pixels)
obj_pw: 1.0  # obj BCELoss positive_weight
iou_t: 0.20  # IoU training threshold
anchor_t: 4.0  # anchor-multiple threshold
# anchors: 3  # anchors per output layer (0 to ignore)
fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
hsv_h: 0.015  # image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # image HSV-Value augmentation (fraction)
degrees: 0.0  # image rotation (+/- deg)
translate: 0.1  # image translation (+/- fraction)
scale: 0.9  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.5  # image flip left-right (probability)
mosaic: 1.0  # image mosaic (probability)
mixup: 0.1  # image mixup (probability)
copy_paste: 0.0  # segment copy-paste (probability)
```

Cada predi√ß√£o feita com o YOLO, retorna um vetor Nx1 de pelo menos N = 6, do qual cont√©m primeiro a predi√ß√£o da exist√™ncia de um objeto geral, as coordenadas do centro da bounding box do objeto e suas dimens√µes X e Y, e para cada classe existente no modelo, cont√©m uma variavel que indica sua exist√™ncia na imagem:

![alt text](images/vector.png)

## M√≥dulo B√°sico: 3
Implementa√ß√£o do modelo:

```python
model = torch.hub.load('ultralytics/yolov5', 'yolov5s') #Cria inst√¢ncia do modelo a partir de modelo pr√© treinado pela ultralytics
```
![alt text](images/zidane.jpg)

```python
img = "/yolov5/data/images/zidane.jpg"
results = model(img)
results.print()
```

```
image 1/1: 720x1280 2 persons, 2 ties
Speed: 79.9ms pre-process, 298.7ms inference, 15.2ms NMS per image at shape (1, 3, 384, 640)
```

```python
%matplotlib inline 
plt.imshow(np.squeeze(results.render()))
plt.show()
```

![alt text](images/zidaneyoloed.png)

## M√≥dulo B√°sico: 4
Implementa√ß√£o do modelo para par√¢metros de teste alterados:
Para este m√≥dulo j√° foi utilizado um dataset custom, que ser√° abordado mais a fundo nos pr√≥ximos passos.

Treino Vanilla:
--img 320 --batch 8 --epochs 40 
IoU Threshold = 0.2

![alt text](images/snailVanilla.png)

Treino Vanilla:
--img 640 --batch 8 --epochs 40 
IoU Threshold = 0.5

![alt text](images/snailCustom.png)

Podemos perceber que ao aumentar a resolu√ß√£o de entrada das imagens e o limite de IoU, a predi√ß√£o se tornou um pouco melhor, mesmo assim podemos dizer que este modelo n√£o √© capaz de reconhecer e localizar os objetos com facilidade.

## M√≥dulo Especifico: TREINAMENTO DETEC√á√ÉO 2D
* Snail Dataset:
Para a realiza√ß√£o deste m√≥dulo, foi criado um dataset personalizado chamado de Snail Dataset, contendo 40 frames retirados de diferentes epis√≥dios do cartoon americano "Hora de Aventura", frames esses que cont√©m pequenos "easter eggs" de uma lesma.
O dataset foi subdivido para 28 imagens de treinamento, 8 imagens de valida√ß√£o e 4 imagens de teste.
A rotula√ß√£o de cada um dos frames foi feito atrav√©s da ferramenta LabelImg, onde cada lesma foi selecionada e rotulada manualmente.

![alt text](images/snaildataset.jpg)

```python
model = torch.hub.load('ultralytics/yolov5', 'custom', path='\snail.pt', force_reload=True) #Gera o modelo a partir dos dados de treinamento com o Dataset Snail
```

```python
img = "/yolov5/data/images/snailtest.jpg"
results = model(img)
results.print()
```

```python
%matplotlib inline 
plt.imshow(np.squeeze(results.render()))
plt.show()
```

```python
image 1/1: 640x616 (no detections)
Speed: 317.6ms pre-process, 76.4ms inference, 3.0ms NMS per image at shape (1, 3, 640, 640)
```

![alt text](images/snailvanillarun.png)


* BCCD YOLO Dataset:
Com o fracasso do treinamento do Snail Dataset, o foco da detec√ß√£o foi alterado para o √¢mbito biol√≥gico, ent√£o o novo dataset a ser utilizado foi o bccD (Blood Cell Counting & Detection), contendo 360 imagens no total (240 de treino, 60 de valida√ß√£o e 60 de teste), compreendendo 3 classes de objetos: White Blood Cells, Red Blood Cells e Platelets

![alt text](images/bccddataset.jpg)

```python
model = torch.hub.load('ultralytics/yolov5', 'custom', path='\bccd.pt', force_reload=True) #Gera o modelo a partir dos dados de treinamento com o Dataset BCCD
```

```python
img = "/yolov5/data/images/bccdtest.jpg"
results = model(img)
results.print()
```

```python
%matplotlib inline 
plt.imshow(np.squeeze(results.render()))
plt.show()
```

```python
image 1/1: 480x640 1 Platelets, 21 Red Blood Cellss, 1 White Blood Cells
Speed: 14.0ms pre-process, 173.5ms inference, 7.0ms NMS per image at shape (1, 3, 480, 640)
```

![alt text](images/bccdvanillarun.png)

## M√≥dulo Especifico: Pr√©-Processamento
Ap√≥s a implementa√ß√£o e treinamento "vanilla" do modelo, foram utilizados diversos m√©todos para tentar aumentar acur√°cia das detec√ß√µes, para tal utilizou-se da ferramenta Roboflow para gerar novos dados atrav√©s de Data Augmentation.
O processo se d√° quando criam-se novas imagens que podem ser utilizadas para treinamento e/ou valida√ß√£o, atrav√©s de distor√ß√µes das imagens j√° existentes, esse processo al√©m de aumentar a quantidade de dados, aumenta tamb√©m os graus de liberdade de posi√ß√£o no qual o modelo √© capaz de reconhecer as classes.

* Snail Dataset:
Inicio: 28 de treino, 8 de valida√ß√£o e 4 de teste
Depois de aplicar Data Augmentation:  84 de treino, 8 de valida√ß√£o e 4 de teste
Pr√© Processamento: Auto-Orient + Stretch to 416x416
Data Augmentation: Flip: Horizontal, Vertical + 90¬∞ Rotate: Clockwise, Counter-Clockwise, Upside Down + Crop: 0% Minimum Zoom, 43% Maximum Zoom + Saturation: Between -67% and +67% + Mosaic + Bounding Box: Flip: Horizontal, Vertical

![alt text](images/snailcomparisson.png)

* BCCD Dataset:
Inicio: 240 de treino, 60 de valida√ß√£o e 60 de teste
Depois de aplicar Data Augmentation: 720 de treino, 60 de valida√ß√£o e 60 de teste
Pr√© Processamento: Auto-Orient
Data Augmentation: Flip: Horizontal, Vertical + 90¬∞ Rotate: Clockwise, Counter-Clockwise + Rotation: Between -30¬∞ and +30¬∞ + Shear: ¬±15¬∞ Horizontal, ¬±15¬∞ Vertical

![alt text](images/bccdcomparisson.png)

## M√≥dulo Especifico: Fine Tuning
Para o acompanhamento em tempo real do treinamento de cada um dos modelos, foi utilizada a ferramenta WandB, ferramenta que permite acompanhar a evolu√ß√£o de m√©tricas enquanto o modelo ainda segue em treinamento, a partir dela podemos tamb√©m comparar diferentes resultados de diferentes treinamentos e datasets.



## Performance do Modelo
BCCD Vanilla:
*	**Precision** : 0.56264
*	**box_loss**: 0.04872
*	**cls_loss**: 0.00785
*	**obj_loss**: 0.14802

BCCD Augmented:
*	**Precision** : 0.78559
*	**box_loss**: 0.03540
*	**cls_loss**: 0.00268
*	**obj_loss**: 0.14197

Snail Dataset Vanilla:
*	**Precision** : 0.00194
*	**box_loss**: 0.11223
*	**cls_loss**: 0
*	**obj_loss**: 0.02152

Snail Dataset Augmented:
*	**Precision** : 0.03351
*	**box_loss**: 0.08506
*	**cls_loss**: 0
*	**obj_loss**: 0.02645

## Conclus√£o 
O algoritmo YOLO se mostra ser de f√°cil implementa√ß√£o e manipula√ß√£o, sendo capaz de reconhecer e localizar diferentes classes de objetos em uma imagem com ligeira facilidade e pouco poder de processamento, apesar de ter dificuldade em reconhecer objetos pequenos em imagens "desenhos 2d", apresenta sim uma boa precis√£o e confiabilidade em predi√ß√µes. 


